### analyzedb 收集统计信息

~~~
 -d <database name>    Database name. Required.
  -s <schema name>      Specify a schema to analyze. All tables in the schema
                        will be analyzed.
  -t <schema name>.<table name>
                        Analyze a single table. Table name needs to be
                        qualified with schema name.
  -i <column1>,<column2>,...
                        Columns to include to be analyzed, separated by comma.
                        All columns will be analyzed if not specified.
  -x <column1>,<column2>,...
                        Columns to exclude to be analyzed, separated by comma.
                        All columns will be analyzed if not specified.
  -f <config_file>, --file=<config_file>
                        Config file that includes a list of tables to be
                        analyzed. Table names must be qualified with schema
                        name. Optionally a list of columns (separated by
                        comma) can be specified using -i or -x.
  -l, --list            List the tables to be analyzed without actually
                        running analyze (dry run).
  -p <parallel level>   Parallel level, i.e. the number of tables to be
                        analyzed in parallel. Valid numbers are between 1 and
                        10. Default value is 5.
  --skip_root_stats     Skip refreshing root partition stats if any of the
                        leaf partitions is analyzed.
  --gen_profile_only    Create cached state files to indicate specified table
                        or all tables have been analyzed.
  --full                Analyze without using incremental. All tables
                        requested by the user will be analyzed.
  --clean_last          Clean the state files generated by last analyzedb run.
                        All other options except -d will be ignored.
  --clean_all           Clean all the state files generated by analyzedb. All
                        other options except -d will be ignored.
  -h, -?, --help        Show this help message and exit.
  -v, --verbose         Print debug messages.
  -a                    Quiet mode. Do not prompt for user confirmation.
<u>下划线</u>
~~~





### GP master 主备(gpadmin用户运行)

#### 1、创建master镜像

1. 在镜像master配置环境变量：vim ~/.bashrc

~~~
PATH=$PATH:$HOME/bin
export PGPORT=5432
export MASTER_DATA_DIRECTORY=/data/greenplum/gpmaster/gpseg-1
source /usr/local/greenplum/greenplum-db/greenplum_path.sh

export PGDATABASE=testdb

export PATH
~~~

2. 在镜像master配置免密：在/home/gpadmin下创建all_nodes文件，添加集群所有节点

   设置GP环境生效：source /usr/local/greenplum/greenplum-db-5.19.0/greenplum_path.sh

   设置GP环境免密：gpssh-exkeys -f all_nodes

   ~~~
   [STEP 1 of 5] create local ID and authorize on local host
     ... /home/gpadmin/.ssh/id_rsa file exists ... key generation skipped
   
   [STEP 2 of 5] keyscan all hosts and update known_hosts file
   
   [STEP 3 of 5] authorize current user on remote hosts
     ... send to centos01
     ... send to centos03
   
   [STEP 4 of 5] determine common authentication file content
   
   [STEP 5 of 5] copy authentication files to all remote hosts
     ... finished key exchange with centos01
     ... finished key exchange with centos03
   
   [INFO] completed successfully
   ~~~

   验证GP集群免密：gpssh -f all_nodes 

   ~~~
   => pwd
   [centos01] /home/gpadmin
   [centos02] /home/gpadmin
   [centos03] /home/gpadmin
   => 
   ~~~

3. 在镜像master节点创建数据目录：mkdir -p /data/greenplum/gpmaster
4. 在主master运行命令：gpinitstandby -s centos02

~~~
gpadmin-[INFO]:-Validating environment and parameters for standby initialization...
gpadmin-[INFO]:-Checking for filespace directory /data/greenplum/gpmaster/gpseg-1 on centos02
gpadmin-[INFO]:------------------------------------------------------
gpadmin-[INFO]:-Greenplum standby master initialization parameters
gpadmin-[INFO]:------------------------------------------------------
gpadmin-[INFO]:-Greenplum master hostname               = centos01
gpadmin-[INFO]:-Greenplum master data directory         = /data/greenplum/gpmaster/gpseg-1
gpadmin-[INFO]:-Greenplum master port                   = 5432
gpadmin-[INFO]:-Greenplum standby master hostname       = centos02
gpadmin-[INFO]:-Greenplum standby master port           = 5432
gpadmin-[INFO]:-Greenplum standby master data directory = /data/greenplum/gpmaster/gpseg-1
gpadmin-[INFO]:-Greenplum update system catalog         = On
gpadmin-[INFO]:------------------------------------------------------
gpadmin-[INFO]:- Filespace locations
gpadmin-[INFO]:------------------------------------------------------
gpadmin-[INFO]:-pg_system -> /data/greenplum/gpmaster/gpseg-1
ialization? Yy|Nn (default=N):
> y
gpadmin-[INFO]:-Syncing Greenplum Database extensions to standby
gpadmin-[INFO]:-The packages on centos02 are consistent.
gpadmin-[INFO]:-Adding standby master to catalog...
gpadmin-[INFO]:-Database catalog updated successfully.
gpadmin-[INFO]:-Updating pg_hba.conf file...
gpadmin-[INFO]:-pg_hba.conf files updated successfully.
gpadmin-[INFO]:-Updating filespace flat files...
gpadmin-[INFO]:-Filespace flat file updated successfully.
gpadmin-[INFO]:-Starting standby master
gpadmin-[INFO]:-Checking if standby master is running on host: centos02  in directory: /data/greenplum/gpmaster/gpseg-1
gpadmin-[INFO]:-Cleaning up pg_hba.conf backup files...
gpadmin-[INFO]:-Backup files of pg_hba.conf cleaned up successfully.
gpadmin-[INFO]:-Successfully created standby master on centos02
~~~

5. 查看集群状态：gpstate

~~~
[INFO]:-Greenplum instance status summary
[INFO]:-----------------------------------------------------
[INFO]:-   Master instance                                           = Active
[INFO]:-   Master standby                                            = centos02
[INFO]:-   Standby master state                                      = Standby host passive
[INFO]:-   Total segment instance count from metadata                = 8
[INFO]:-----------------------------------------------------
[INFO]:-   Primary Segment Status
[INFO]:-----------------------------------------------------
[INFO]:-   Total primary segments                                    = 4
[INFO]:-   Total primary segment valid (at master)                   = 4
[INFO]:-   Total primary segment failures (at master)                = 0
[INFO]:-   Total number of postmaster.pid files missing              = 0
[INFO]:-   Total number of postmaster.pid files found                = 4
[INFO]:-   Total number of postmaster.pid PIDs missing               = 0
[INFO]:-   Total number of postmaster.pid PIDs found                 = 4
[INFO]:-   Total number of /tmp lock files missing                   = 0
[INFO]:-   Total number of /tmp lock files found                     = 4
[INFO]:-   Total number postmaster processes missing                 = 0
[INFO]:-   Total number postmaster processes found                   = 4
[INFO]:-----------------------------------------------------
~~~

6. 当主master故障激活standby master：在standby master上运行命令：

   gpactivatestandby -d /data/greenplum/gpmaster/gpseg-1

~~~
[INFO]:------------------------------------------------------
[INFO]:-Standby data directory    = /data/greenplum/gpmaster/gpseg-1
[INFO]:-Standby port              = 5432
[INFO]:-Standby running           = no
[INFO]:-Force standby activation  = yes
[INFO]:------------------------------------------------------
n (default=N):
> y
[INFO]:-Starting standby master database in utility mode...
[INFO]:-Updating transaction files filespace flat files...
[INFO]:-Updating temporary files filespace flat files...
[INFO]:-Reading current configuration...
[DEBUG]:-Connecting to dbname='testdb'
[INFO]:-Writing the gp_dbid file - /data/greenplum/gpmaster/gpseg-1/gp_dbid...
[INFO]:-But found an already existing file.
[INFO]:-Hence removed that existing file.
[INFO]:-Creating a new file...
[INFO]:-Wrote dbid: 1 to the file.
[INFO]:-Now marking it as read only...
[INFO]:-Verifying the file...
~~~

#### 2、将故障master重新加入集群，作为standby节点

1. 先备份之前的主节点数据

~~~
mv /data/greenplum/gpmaster/gpseg-1 /data/greenplum/gpmaster/gpseg-1_bak20200110
~~~

2. 将节点作为standby加入集群

~~~
gpinitstandby -s  故障节点主机名
~~~

3. 如果想在切换的同时创建一个新的Standby，可以执行如下命令

~~~
gpactivatestandby -d /data/greenplum/gpmaster/gpseg-1 -c new_standby_hostname
~~~



#### 3、查询

~~~
-- 显示表
tpchdb=# \d+
                                   List of relations
 Schema |          Name          |   Type   |  Owner  | Storage |  Size   | Description 
--------+------------------------+----------+---------+---------+---------+-------------
 public | customer               | table    | gpadmin | heap    | 160 kB  | 
 public | customer_c_custkey_seq | sequence | gpadmin | heap    | 160 kB  | 
 public | lineitem               | table    | gpadmin | heap    | 160 kB  | 
 public | nation                 | table    | gpadmin | heap    | 0 bytes | 
 public | nation_n_nationkey_seq | sequence | gpadmin | heap    | 160 kB  | 
 public | orders                 | table    | gpadmin | heap    | 160 kB  |
 
 -- 执行sql文件
 tpchdb=# \i /home/gpadmin/2.18.0_rc2/dbgen/dss/templates/1.sql                                                                                                             
 l_returnflag | l_linestatus | sum_qty | sum_base_price | sum_disc_price | sum_charge | avg_qty | avg_price | avg_disc | count_order 
--------------+--------------+---------+----------------+----------------+------------+---------+-----------+----------+-------------
(0 rows)

-- 更换数据库
testdb=# \c tpchdb;
You are now connected to database "tpchdb" as user "gpadmin".
tpchdb=# 
~~~





